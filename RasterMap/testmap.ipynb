{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "ops = {'nclust': 30, # number of clusters\n",
    "       'iPC': np.arange(0,200).astype(np.int32), # number of PCs to use\n",
    "       'upsamp': 100, # upsampling factor for embedding position\n",
    "       'sigUp': 1 # standard deviation for upsampling\n",
    "      }\n",
    "\n",
    "S = np.load('C:/Users/carse/github/bigdat/spks.npy')\n",
    "iscell = np.load('C:/Users/carse/github/bigdat/iscell.npy')\n",
    "S = S[iscell[:,0].astype(np.bool),:]\n",
    "print(S.shape)\n",
    "\n",
    "S = S - S.mean(axis=1)[:,np.newaxis]\n",
    "\n",
    "# compute svd and keep iPC's of data\n",
    "u,sv,v = np.linalg.svd(S, full_matrices=0)\n",
    "isort = np.argsort(u[:,0]).astype(np.int32)\n",
    "\n",
    "\n",
    "iPC = ops['iPC']\n",
    "S = u[:,iPC] @ np.diag(sv[iPC])\n",
    "NN,nPC = S.shape\n",
    "nclust = ops['nclust']\n",
    "nn = np.floor(NN/nclust) # number of neurons per cluster\n",
    "iclust = np.zeros((NN,),np.int32)\n",
    "# initial cluster assignments based on 1st PC weights\n",
    "iclust[isort] = np.floor(np.arange(0,NN)/nn).astype(np.int32)\n",
    "iclust[iclust>nclust] = nclust\n",
    "# annealing schedule for embedding\n",
    "sig_anneal = np.concatenate((np.linspace(nclust/10,1,50),np.ones((50,),np.float32)), axis=0)\n",
    "\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from matplotlib import pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "t=0\n",
    "for sig in sig_anneal:\n",
    "    V = np.zeros((nPC,nclust), np.float32)\n",
    "    # compute average activity of each cluster\n",
    "    for j in range(0,nclust):\n",
    "        iin = iclust==j\n",
    "        V[:,j] = S[iin,:].sum(axis=0)\n",
    "    V = gaussian_filter1d(V,sig,axis=1,mode='reflect') # smooth activity across clusters\n",
    "    V /= ((V**2).sum(axis=0)[np.newaxis,:])**0.5 # normalize columns to unit norm\n",
    "    cv = S @ V # reproject onto activity across neurons\n",
    "    # recompute best clusters\n",
    "    iclust = np.argmax(cv, axis=1)\n",
    "    cmax = np.amax(cv, axis=1)\n",
    "    if t>0:\n",
    "        score = ((cmax - cmax0)**2).sum()\n",
    "        print(score)\n",
    "    cmax0 = cmax\n",
    "    t+=1\n",
    "\n",
    "\n",
    "def upsampled_kernel(nclust, sig, upsamp):\n",
    "    xs = np.arange(0,nclust)\n",
    "    xn = np.linspace(0, nclust-1, nclust * upsamp)\n",
    "    d0 = (xs[:,np.newaxis] - xs[np.newaxis,:])**2;\n",
    "    d1 = (xn[:,np.newaxis] - xs[np.newaxis,:])**2;\n",
    "    K0 = np.exp(-1*d0/sig)\n",
    "    K1 = np.exp(-1*d1/sig)\n",
    "    Km = K1 @ np.linalg.inv(K0 + 0.001 * np.eye(nclust));\n",
    "    return Km\n",
    "\n",
    "Km = upsampled_kernel(nclust,ops['sigUp'],ops['upsamp'])\n",
    "iclustup = np.argmax(cv @ Km.T, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(iclustup)\n",
    "isort = np.argsort(iclustup)\n",
    "print(iclustup.max())\n",
    "ssmooth = scipy.stats.zscore(gaussian_filter1d(S[isort,:],10,axis=0),axis=1)\n",
    "#plt.imshow(Km[:300,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "plt.figure(figsize=(16,16))\n",
    "plt.imshow(ssmooth,vmin=0,vmax=3)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
